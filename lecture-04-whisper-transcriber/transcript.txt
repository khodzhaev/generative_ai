 Good evening, guys. Good evening. Hello. Do you choose the. Mr. Stage is all or not yet. I choose the team. Maybe to the. Oh, sure. Today's the deadline. By the way, do we have strict delays for homework, guys? No, isn't that strict? Because I'm not. I did. But I would suggest to find at least like 10 to 15 minutes every day. How I am because when it will come at the end. It will be like everything, you know, so at least I'm just trying to find 10 to 15 20 minutes doing doing like by small, small, small parts. Then I think. I'm more from this course or from others. Any I think. Other courses I think didn't give you homework yet. Yeah, they give it. Data data processing they gave it gave he gave yesterday. I think this file formats. I yesterday I missed the classes. I will watch it. Hey, yes. Hello, Italy. All right. I have a question. I'm a feature. If you see, so two days ago, Google introduced quantum computers. Yeah, our second lesson you said that there is a problem with the model because they have a resource problem. And what will be in the future about it? Because if Google, if we have, they have a quantum computers, I mean, they have a huge result results. And how they will. Yeah, so that's that's really good. It's interesting question. So I don't know how they work like only very general concept of these cubies. I still, you know, I've been studying quantum physics in university, like at least one year, probably two years. I can't remember. So a lot of electronics works on quantum effects. So for example, some some staff allows the electrons to jump the barrier. They like actually cannot jump so they like tunneling through that. And no, no, it's like how it works, but it works and we use it in TVs and smartphones. Like some kind of some kind of magic. It's still I think they should be some kind of scientific explanation that. I don't know like how these quantum computers work. I don't understand the concept of like something having the value of zero and one at the same time because like, okay. You can imagine that, but how about the storage, right? So if I talk about like HDD or SSD, any storage, so you need to write it. And you need to like you should be able to read it in the future. And the most fear like two fears I remember like from the community regarding quantum computers is, okay, if they are so like powerful and can make like much more like, I don't know, millions times, computations per second. So I don't know about the encryption, right? So every say or any other encryption algorithm. So basically encryption works like modern encryption works on the very basic example like. There are how how is called like one way function in mass. I don't know how it's in English. So the way like it's very easy to calculate this, for example, it's very easy to multiply to prime integers and get the result, but it's super hard to understand like what. What are the integers you multiply it if you received like this result and. A lot of encryption is based on that and actually Bitcoin is based on that so Bitcoin has several like Bitcoin has a lot of protocols inside like technologies and most of them like top tier encryption we have right now. So if Google can beat that so they can possibly like hijack all the new bitcoins. Maybe they can rewrite the whole Bitcoin like the whole blockchain like in a day and I didn't know like still all the bitcoins from us. So a lot of like military applications like all this encryption and networking. I don't know it's technically possible that the such technology can can appear, but. Taking an account how much time and money and resources and smart people it takes to build such thing. Maybe the first country which bills it and then like will create some kind of like snow crash like from cyberpunk books I don't know so we'll see. Please like I know like from from from what I understand like I T history and technology history like all the new like top tier technologies they have like two applications like the two industries basically driving them fast in and like making them broadly available is. So this is like two things usually picking up the latest stage and trying to get like money of that and maybe one of them will pick it up I don't know maybe military first. I think I can see any applications of quantum stuff yeah but from personal perspective like being a human like I don't know like I see guys so yeah that's interesting but unless I cannot benefit from that I can as unless I cannot like earn money doing that so it's inevitable for me like the sun the sun just can stop I don't know like okay. For example because the earth's rate is close to sun so the earth can just stop rotating and it will be infinite night for me so I can do anything about that I can do anything about rain so what I can this just to to buy them braille or I don't know prayed during steps sometimes so. In case I have the problem or some something I cannot influence I think it's good not to worry about it because if you worry about something you cannot change that's bad so you spent a lot of resources and the other example be nothing like for sure so my plan is just read the news I don't know follow this agenda but don't worry about it. Okay yeah let's let's get down to business so let me try to open my upon our schedule I have to reboot my BC today so I lost this X was precious. Okay this one. Okay so the good news good news we are on track right and here we are meeting number five so today we're going to discuss with the API and local installation. The bad news I took a look at some of the Chromeworks like two or three maybe five but not like very very high level I like the blog posts you guys made so I like the pictures and I think I will share some of my favorite pictures next time so I assume I will need this weekend to check them and probably to add in the next set some marks or something like that so. Just give me some time but I haven't found any like critical problems there so just remember to to share the workflow how you how you did that like for the first task so I need to see like what prompts you've been using and don't forget about the pictures so the pictures unnecessary for our blog post. So I think we're going to focus on on that probably either on this lecture or this one we're going to have time to review the homework so what today we're going to discuss with this very and this is very. Let me show this slide so here here are the slides for today. So what is the visper and why we're discussing that so mostly when people discuss the generator for you or yeah in general so a focus stone like LLAMs, I know like a pilot functions and stuff like that so everything that works with text right because it has more application to the business when you work with text but still usually what is being forgotten. So the question is images and audio processing can't get in the images I can't say this like easier to monetize this so not to my business applications so I know a lot of I know a lot of cases where clients came to us like to do palm and ask to create something like I don't know maybe I read over a hundred of cases. Like only several them related to image generation but some of them like more modest case more of these cases are related to audio and one of the usual request is okay guys we have 5000 hours of recordings of I don't know meetings or customers calling us for the support so we need to understand this data right. So imagine you have a first line support like people calling like real users calling describing the issue and the operators are just sharing what what should you do to solve it and you need to to control it somehow right so you need to see what are the most of the questions so what are the answers so is the client is happy or not right and for this case you need to voice processing and processing the voices actually very old technology. I don't remember how old it is but like two two things here usually working is text to speech to text and if we check I didn't know like let's check Asia or text to speech okay say yeah is patient all right I got it everything is a yeah now let me check the price and actually. DTS pricing it's super cheap it's super cheap okay I think here. So this is okay free tier all right basically all right didn't need this one so speech to text so in order to transcript something like if you have a phone call real time transcription one dollar per hour that's too much. Okay by transcription so if I have a lot of audio calls I didn't know like one agreed I can post them as a batch and this will result me in 80 cents per hour so not too much actually. Yeah as usually like Microsoft is like very complicated well very complicated stuff for billing so it's hard to understand how much you will spend yeah and here is like text to speech so basically to two directions like from speech you can extract text and from text you can generate speech right and this is like the standard voice. I think this standard voice become near all like during like last year because previously they had different. They had a different pricing like the standard voice is like this robotized voice usually here when you call a bank or something and neural voice is like more pleasant more realistically more naturally the tone so right now I don't think. They should have some kind of like cheap voice like this old cheap voice probably it's inside the easy way studio but the trick is it's not expensive right so one billion characters is like it's a lot. $15 for business it's like well not too much I think so and in case we have 1000 of like phone calls transcript it so it will result as is only like less than $200 so that's that's acceptable for that and they they definitely use machine learning there right so because there's no way programmatically like algorithmically. To describe this piece but still the interesting thing here is it's also possible to use machine learning techniques and all this concept of token we've been discussing previously right in in working with speech in understanding this speech and the project the project I would like to show you this with so. Let me find it should be here in the notes I put. Yeah this one. It wasn't introduced very similar once the child GPT arrived right so. I just trying to recognize what was the time when child GPT released okay. November 30 alright 2022 yeah so they introduced this per like couple of months before change it into know what happens like. Do you remember this movie settings floor. This one so do you know this movie. It's kind of like popular from scientific perspective but they big up the problem right so this is the cyber like not so cyberpunk but probably like. Interesting science fiction but take a look at the release years 1999 the problem is that in 1999 this movie gets out matrix and that's why like everyone know about the matrix it was like very successful movie and this is the reason. So much more less people know that this movie for even exists if they are all is it like a year previous before matrix so much more success on the same business with the right so child GPT early is November 30 and this per actually the same company open here but it was not so hyped. In September as it become in November right so what they introduced is they actually been working like at the same time looks like. Maybe working at the visper and parallel like working with Shazup is right so they reused the same like not the same but similar architecture like in quarters decoders and tokens to predict the tokens but not from. Text but from audio as well so they just take a look at the audio right and in the paper so they share like. This one so they took. 680 thousand hours of multilingual audio so they sliced it in 30 seconds time like steps not steps but chunks and they they trained the model the trend the model against it using the same approach. The use for the GPT so pretty the same like slice the data into some samples try to predict the tokens like compare with the result learn trained the model and so on so and this results in very interesting thing very high quality and I don't know if there any model right now which can be it's equality of whisper. Because once it was released it was like very high quality they released another model couple of months ago I think it's called this particular but their texture seems to stay to stay the same so and one more interesting thing here is it's completely open sourced so you can download it and it doesn't require a lot of VRAM to run so you can run it. On the GPU you can run it a bit slower on the CPU and as far as it's like not large language model it will perform like with acceptable acceptable speed I've been running it at the CPU once and it works normally so not so slow as the LLM. We are not so interested in technical details and I don't understand them actually just to explain to you but what we're interested in is actually we're interested in the result right so how it works and how I can use it so how how to use it so you just install it as a Python package but you need the bite or and this is like why I mentioned the bite or previously so in order to install it locally. So you must have the PyTorch and this is the command which should be PyTorch download probably now come on where's download get started here install okay like if you would like to try this per right or in future if you would like to work with PyTorch so there's like two options here. So it doesn't matter which version you will be installing you're going to see the same table for every time like it's couple of years the same so if installing it like in straightforward like recommended way like usually it's windows, Python, Tech Azure, people, Python and here is like CUDA or CPU and depending on what you will sell it. So if you select the URL will be different right so CUDA is the accelerated computing framework created by Nvidia as far as I remember by Nvidia to run the computations on the GPU and if you download and install this PyTorch you will be running everything against the GPU but if you do not have GPU right so you can install it without like just the CPU and it will be the same PyTorch it would work the same but much more slow right but it will still work so you need to you need to prior to install the PyTorch so first you need to Python next you need to select the CUDA version so usually the later the better you just copy this and style and actually I did that today because my PyTorch but not PyTorch but VSPR failed to run today so I've been preparing to the demo and I also have like the some files, audio files so and the problem is why facing them and you may face the same so let me show you so the problem with Python is that somehow like for for modern applications I use numpy version 2 so numpy is a framework is a library to working like with numbers in Python and it's required by PyTorch but this this PyTorch and it's like implementation in VSPR doesn't work with numpy 2.0.2 so it requires like old version and that's that's kind of problem you may face as well so what I did is actually I installed like virtual environment so I created a virtual Python environment and downloaded once again PyTorch, VSPR and all this stuff so at least now it works right so that's that's the problem you may face with working with any software in Python at least I think they should be some kind of work around but taking a look at how many people using the virtual environments I think this is the acceptable work around so getting back here so what you need is just to install the library and that's it you can install it from source but I prefer like this lazy option and it also requires FFMPEG so FFMPEG this this is the most popular library to working with audio and video so and actually this may be useful for you in future so I know like working in development or just processing media like audio and video requires you to convert files from one format to another, split them I don't know change the bitrate and anything so everything can be used in the library anything so everything can be done with it FFMPEG but FFMPEG is a command line interface like it's a program which allows you to do everything but without the user interface without the UI but you can you can work with it programmatically so for example this is how you can convert from NB4 to AV like the old format right and this is like the the greatest software and the fastest solution right now I think so a lot of audio and video converting software use FFMPEG and the good so it will be necessary as well if you would like to start with whisper because whisper will need to transform the data from one format to another so for example in my example I'm going to use MP3 but in some cases it may be one format or something like that so this will need to transform from one format to another and here are the models and languages so as far as it's machine learning model right so you can pick up any model and getting back here so remember we've been discussing this like model card, quantization, distillation and so on so different models right so this is like 13 billion model this is 70 billion model the same with whisper so this model has 39 million parameters it's tiny and it requires only one gigabyte of video RAM like VRAM and it's very fast right so assuming the large model has like 1.5 billion parameters it will occupy 10 gigabytes of VRAM and the speed is 1 like 1x right so this one is 10 times faster and turbo is 8 times faster and that's it they have large V2 and large V3 and what's more interesting here is the quality so the quality here is measured in WER like World error rate so it just evaluating how much how many words like mispredicted like how many words are wrong and you can you can see the languages here so depending on the data set and probably the language structure this really differs right so I'm not surprised this paniche is the has like less errors than any other languages because Spanish at least from my perspective I know like a couple of words and it's it looks like very easy language right like straightforward and kind of easy yeah and some of the languages probably like in the presence in the internet will result in like half of the words misspelled like Belarusian I don't know I think I need to I know Belarusian language and I think I need to find some podcast in Belarusian and try to feed it into the whisper and check like it works but this someone strange because 42 out of 100 agreed comparing to six in Ukrainian so Belarusian Ukrainian super similar super similar so I can understand like 90% of Ukrainian and Ukrainians understand 90% of Belarusian probably is the problem in the data set right okay but in case like in most cases we're going to work with English right so working with these languages super cool and a common line usage is pretty easy so let's run the let's run the example and for the example I have the I took the matrix movie and you know like there is a scene I just meet a stocking with more foods let me just let's fix agents meet his his delivering the speech about like the humans I'm not sure you will be able to to hear it because I'm using teams in in browser so it's not desktop applications so I can't share my audience my audio but here is like the agents meet is interrogating more feels and he's delivering the speech like I got the idea so human beings are a virus and we like the agents are the cure so I will drop you the link or you can just google it and and reconsider this is I picked this this sample because like high quality speech and know any like music and background and something like that so let me try to run this and check how it will work so default whisperer just need to call whisper and pass the parameter as the the data file so right now is detecting the language is in first 30 seconds and the language is detected to English so you can do that actually you can specify the language and here is the output right so this is like the Smith is fine. Discussing it this is very precise actually this is very precise I think it's like probably here we have the problems. Yeah I think it's missing it's missing something still but I don't know what model I'm using so let me call the. The usage. Okay so a lot of things here so we are interested in the model so we can specify the model from here right so these are the available models I don't know which one is the default maybe small or base so I'm going to use it. So I have a lot of VRAM so I can actually launch large model so let's try with probably another model and you can also specify the language explicitly I don't think it will help us because it automatically recognized the business English one more thing actually very interesting thing you can do with whisper so here should be a parameter which is called. What prompt you find it. Tress estimation okay model device output we're both. The should be parameter which is called something like a prompt. No. Yeah this one initial prompt so the trick is so by default it's not but let's get back to the idea so whisper. So whisper works with tokens right and everything like in this architecture you can you can pass the system message so you can pass the system message and whisper. I've been working once on English transcription task so we decided to make. To transcribe the English assessments and other companies so there is like an interviewer asking questions and the person replying and one of the idea was to calculate the. I don't know how it's called like the words like when the person is thinking like parasite words so it's not possible to do with just playing with her hardly possible but if you explicitly provide them in a prompt it will recognize them and also a lot of a lot of times in this dialogue they were mentioned to a company name e palm and. There is no such word in in whisper data set so that's why. It was looking for similar but if you provide it in the initial prompt and it will like see this the same token combination it will just do not search for any other alternative so this is very powerful thing like I'm very underrated. Okay so let's get back here and let's try the model let me try different models and we're going to see the performance like this speed. Let's try with tiny smallest model and let's check how fast to work. Pretty fast. And let me try. Okay pretty fast as well I don't see a big difference in speed here right at least at this sample the sample is on the one minute. No okay yeah the final talking was. Took the time and let me try large. So the large should give us the highest quality. Okay yeah you see the difference so large and turbo versus the tiny so the tiny. You can't just understand what's what's going on in this discussion so if you don't care about particular worlds if you just would like I don't know to summarize it in future and make some decision like I didn't know. Sentiment analysis something so maybe tiny is okay but still. That's that's a lot of questions as far as I see. But here the turbo and the large so they work very effectively. All right so and once I run every model so it's getting downloaded so I don't think I started small so probably it will be downloading right now. Now it's already downloaded I think yeah so once I selected large first time it started downloading all of this model like one and a half gigabytes of model locally so if you have a lot of files I didn't know million of hours so what you just need. I just need a PC so you can use it in cloud right so let's check the pricing opening a call API pricing so you can do that with API let me scroll to the whisper. I'm tuning real time systems okay images audio models okay so what we're going to pay we're going to pay 0.16 cents per minute so let's let me calculate one hour. So 0.16 cents per minute so it means one hour will cost us 36 cents yeah so it means like 100 hours of transcription will result in 36 dollars so this should be some point where it's cheaper to purchase hardware and run it on your hardware and save the hardware for yourself instead of sending to the. To be to be open the right yeah so in some cases it's more effective to do it on your own machine and in a lake spend the night. Recreate some Python scripts and yeah regarding Python you can call it from Python as well so it's Python library so you can you can use it from common line but you can also here is the common time usage you can also import it. Load the model and transcribe your own data just passing is the reference to the to the file right and here are the examples how we can do that with. With Python still it has one problem which probably be solved in some forks of the whisper like whisper X and so on the problem is it doesn't different shade speakers so you will not see the difference between speaker one and speaker to write. So what I did in homework I shared the file with you where there is a difference between speaker one and speaker so here is no no any difference but the output formers may be different right so. Let me call the help once again. We have output format you can see we have a lot of different output formats TXT VTT SRT TTS VG zone all let's try. Let's try to run with all but probably all is a default right so let me share. Okay yeah all is a default it means I already have all this information available so let's let's check it out if you like J zones you can run this. We can format it very good right.